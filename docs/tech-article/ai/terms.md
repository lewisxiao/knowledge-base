在 AI 领域，也存在一些技术术语，如果理解了这些术语，对于学习 AI 是有很大帮助的，这里对术语做一个记录，方便查阅。

## Embedding
用于将高维空间中的数据转换为低维空间的向量标识，核心原理是降维，但是能保留原始数据中关键的信息和内在结构，使得计算机能更有效地处理数据。

## 噪点

## Token
机器无法像人一样直接地去理解句子、声音、图像，而是通过 Token（词元） 来进行的。

Token 在不同的领域有着不同的含义，在软件开发工程师的眼中，是访问令牌，在其它领域也可能表示为象征、标志、信物等等。而在 AIGC 领域，Token 通常指词元，它是模型中用数字来标识单词的最小单位。

## Diffusion 扩散
Stable Diffusion（简称：SD） 的生图过程是一个反向生图过程，就是将一个全是噪点的图，一层一层地去掉噪点，最后生成出图像的过程。

有反向生图过程，对应也就会有前向过程，Difussion 的前向过程就是模型的预训练过程，通过不断地增加噪点去训练模型对噪点的预测能力。

## 潜空间（Latent Space）
在 潜空间（Latent Space）中可以学习数据的潜在特征，以及如何简化这些特征的表达，以便发现某种规律模式，最终来识别、归类、处理这些数据。

## U-Net

## CLIP（Contrastive Language-Text Pre-Training）
CLIPText 模型可以简称为图文匹配模型，通过对自然语言进行理解、和对计算机视觉分析，并最终对语言和图像之间的对应关系进行比对训练，产生一个预训练模型。

## VAE（Variational Auto Encoder）
变分自动编码器

## 神经网络

## 过拟合与泛化

## GPT（Generative Pre-trained Transformer）
GPT 全称是 Generative Pre-trained Transformer，中文为 生成式预训练转换器 或 生成式预训练变形金刚，可以拆分成 3 个单词去理解：
* G-Generative：说明这个 AI 模型是用来生成内容的
* P-Pre-trained：预训练，说明这个模型经过了大量的训练，能力很强
* T-Transformer：转换器或者变形金刚

## 监督学习、无监督学习、半监督学习、强化学习、自监督学习